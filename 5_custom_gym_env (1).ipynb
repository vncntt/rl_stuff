{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoxOjIlOImwx"
      },
      "source": [
        "# Stable Baselines3 Tutorial - Creating a custom Gym environment\n",
        "\n",
        "Github repo: https://github.com/araffin/rl-tutorial-jnrr19/tree/sb3/\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3-Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn how to use your own environment following the OpenAI Gym interface.\n",
        "Once it is done, you can easily use any compatible (depending on the action space) RL algorithm from Stable Baselines on that environment.\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuDQ3DwmluoA"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sp8rSS4DIhEV",
        "outputId": "0c9a76ce-9ec9-413c-b07b-1eb85bc1011b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3>=2.0.0a4 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading stable_baselines3-2.5.0a0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.0.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.4.0)\n",
            "Collecting cloudpickle (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pandas in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.9.1)\n",
            "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading pygame-2.6.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: psutil in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (6.1.0)\n",
            "Requirement already satisfied: tqdm in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (4.66.4)\n",
            "Collecting rich (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading ale_py-0.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pillow in ./misc/myenv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (10.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./misc/myenv/lib/python3.12/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading grpcio-1.68.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: packaging in ./misc/myenv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (24.1)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading protobuf-5.29.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./misc/myenv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (72.1.0)\n",
            "Requirement already satisfied: six>1.9 in ./misc/myenv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.16.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: filelock in ./misc/myenv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.15.4)\n",
            "Requirement already satisfied: sympy in ./misc/myenv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.13.1)\n",
            "Requirement already satisfied: networkx in ./misc/myenv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./misc/myenv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./misc/myenv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./misc/myenv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./misc/myenv/lib/python3.12/site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./misc/myenv/lib/python3.12/site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.1)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./misc/myenv/lib/python3.12/site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.18.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./misc/myenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./misc/myenv/lib/python3.12/site-packages (from sympy->torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
            "Downloading stable_baselines3-2.5.0a0-py3-none-any.whl (183 kB)\n",
            "Downloading ale_py-0.10.1-cp312-cp312-macosx_11_0_arm64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
            "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
            "Downloading pygame-2.6.1-cp312-cp312-macosx_11_0_arm64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading grpcio-1.68.0-cp312-cp312-macosx_10_9_universal2.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading protobuf-5.29.0-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: farama-notifications, werkzeug, tensorboard-data-server, pygame, protobuf, opencv-python, mdurl, markdown, grpcio, cloudpickle, ale-py, absl-py, tensorboard, markdown-it-py, gymnasium, stable-baselines3, rich\n",
            "Successfully installed absl-py-2.1.0 ale-py-0.10.1 cloudpickle-3.1.0 farama-notifications-0.0.4 grpcio-1.68.0 gymnasium-1.0.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 opencv-python-4.10.0.84 protobuf-5.29.0 pygame-2.6.1 rich-13.9.4 stable-baselines3-2.5.0a0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzevZcgmJmhi"
      },
      "source": [
        "## First steps with the gym interface\n",
        "\n",
        "As you have noticed in the previous notebooks, an environment that follows the gym interface is quite simple to use.\n",
        "It provides to this user mainly three methods, which have the following signature (for gym versions > 0.26)\n",
        "- `reset()` called at the beginning of an episode, it returns an observation and a dictionary with additional info (defaults to an empty dict)\n",
        "- `step(action)` called to take an action with the environment, it returns the next observation, the immediate reward, whether new state is a terminal state (episode is finished), whether the max number of timesteps is reached (episode is artificially finished), and additional information\n",
        "- (Optional) `render()` which allow to visualize the agent in action. Note that graphical interface does not work on google colab, so we cannot use it directly (we have to rely on `render_mode='rbg_array'` to retrieve an image of the scene).\n",
        "\n",
        "Under the hood, it also contains two useful properties:\n",
        "- `observation_space` which one of the gym spaces (`Discrete`, `Box`, ...) and describe the type and shape of the observation\n",
        "- `action_space` which is also a gym space object that describes the action space, so the type of action that can be taken\n",
        "\n",
        "The best way to learn about [gym spaces](https://gymnasium.farama.org/api/spaces/) is to look at the [source code](https://github.com/Farama-Foundation/Gymnasium/tree/main/gymnasium/spaces), but you need to know at least the main ones:\n",
        "- `gym.spaces.Box`: A (possibly unbounded) box in $R^n$. Specifically, a Box represents the Cartesian product of n closed intervals. Each interval has the form of one of [a, b], (-oo, b], [a, oo), or (-oo, oo). Example: A 1D-Vector or an image observation can be described with the Box space.\n",
        "```python\n",
        "# Example for using image as input:\n",
        "observation_space = spaces.Box(low=0, high=255, shape=(HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
        "```                                       \n",
        "\n",
        "- `gym.spaces.Discrete`: A discrete space in $\\{ 0, 1, \\dots, n-1 \\}$\n",
        "  Example: if you have two actions (\"left\" and \"right\") you can represent your action space using `Discrete(2)`, the first action will be 0 and the second 1.\n",
        "\n",
        "\n",
        "[Documentation on custom env](https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html)\n",
        "\n",
        "Also keep in mind that Stabe-baselines internally uses the previous gym API (<0.26), so every VecEnv returns only the observation after resetting and returns a 4-tuple instead of a 5-tuple  (terminated & truncated are already combined to done)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I98IKKyNJl6K",
        "outputId": "b8f464a5-1755-4f04-f820-e7f59c9d5b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
            "Shape: (4,)\n",
            "Action space: Discrete(2)\n",
            "Sampled action: 0\n",
            "(4,) 1.0 False False {}\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# Box(4,) means that it is a Vector with 4 components\n",
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Shape:\", env.observation_space.shape)\n",
        "# Discrete(2) means that there is two discrete actions\n",
        "print(\"Action space:\", env.action_space)\n",
        "\n",
        "# The reset method is called at the beginning of an episode\n",
        "obs, info = env.reset()\n",
        "# Sample a random action\n",
        "action = env.action_space.sample()\n",
        "print(\"Sampled action:\", action)\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "# Note the obs is a numpy array\n",
        "# info is an empty dict for now but can contain any debugging info\n",
        "# reward is a scalar\n",
        "print(obs.shape, reward, terminated, truncated, info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqxatIwPOXe_"
      },
      "source": [
        "##  Gym env skeleton\n",
        "\n",
        "In practice this is how a gym environment looks like.\n",
        "Here, we have implemented a simple grid world were the agent must learn to go always left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rYzDXA9vJfz1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "class GoLeftEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Environment that follows gym interface.\n",
        "    This is a simple env where the agent must learn to go always left.\n",
        "    \"\"\"\n",
        "\n",
        "    # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "    metadata = {\"render_modes\": [\"console\"]}\n",
        "\n",
        "    # Define constants for clearer code\n",
        "    LEFT = 0\n",
        "    RIGHT = 1\n",
        "\n",
        "    def __init__(self, grid_size=10, render_mode=\"console\"):\n",
        "        super(GoLeftEnv, self).__init__()\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        # Size of the 1D-grid\n",
        "        self.grid_size = grid_size\n",
        "        # Initialize the agent at the right of the grid\n",
        "        self.agent_pos = grid_size - 1\n",
        "\n",
        "        # Define action and observation space\n",
        "        # They must be gym.spaces objects\n",
        "        # Example when using discrete actions, we have two: left and right\n",
        "        n_actions = 2\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # The observation will be the coordinate of the agent\n",
        "        # this can be described both by Discrete and Box space\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=self.grid_size, shape=(1,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"\n",
        "        Important: the observation must be a numpy array\n",
        "        :return: (np.array)\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed, options=options)\n",
        "        # Initialize the agent at the right of the grid\n",
        "        self.agent_pos = self.grid_size - 1\n",
        "        # here we convert to float32 to make it more general (in case we want to use continuous actions)\n",
        "        return np.array([self.agent_pos]).astype(np.float32), {}  # empty info dict\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == self.LEFT:\n",
        "            self.agent_pos -= 1\n",
        "        elif action == self.RIGHT:\n",
        "            self.agent_pos += 1\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Received invalid action={action} which is not part of the action space\"\n",
        "            )\n",
        "\n",
        "        # Account for the boundaries of the grid\n",
        "        self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size)\n",
        "\n",
        "        # Are we at the left of the grid?\n",
        "        terminated = bool(self.agent_pos == 0)\n",
        "        truncated = False  # we do not limit the number of steps here\n",
        "\n",
        "        # Null reward everywhere except when reaching the goal (left of the grid)\n",
        "        reward = 1 if self.agent_pos == 0 else 0\n",
        "\n",
        "        # Optionally we can pass additional info, we are not using that for now\n",
        "        info = {}\n",
        "\n",
        "        return (\n",
        "            np.array([self.agent_pos]).astype(np.float32),\n",
        "            reward,\n",
        "            terminated,\n",
        "            truncated,\n",
        "            info,\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        # agent is represented as a cross, rest as a dot\n",
        "        if self.render_mode == \"console\":\n",
        "            print(\".\" * self.agent_pos, end=\"\")\n",
        "            print(\"x\", end=\"\")\n",
        "            print(\".\" * (self.grid_size - self.agent_pos))\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5mlho1-Ine"
      },
      "source": [
        "### Validate the environment\n",
        "\n",
        "Stable Baselines3 provides a [helper](https://stable-baselines3.readthedocs.io/en/master/common/env_checker.html) to check that your environment follows the Gym interface. It also optionally checks that the environment is compatible with Stable-Baselines (and emits warning if necessary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9DOpP_B0-LXm"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_checker import check_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1CcUVatq-P0l"
      },
      "outputs": [],
      "source": [
        "env = GoLeftEnv()\n",
        "# If the environment don't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3khFtkSE0g"
      },
      "source": [
        "### Testing the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i62yf2LvSAYY",
        "outputId": "d2be0861-9353-4ec5-d1c4-b67f10a164e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".........x.\n",
            "Box(0.0, 10.0, (1,), float32)\n",
            "Discrete(2)\n",
            "1\n",
            "Step 1\n",
            "obs= [8.] reward= 0 done= False\n",
            "........x..\n",
            "Step 2\n",
            "obs= [7.] reward= 0 done= False\n",
            ".......x...\n",
            "Step 3\n",
            "obs= [6.] reward= 0 done= False\n",
            "......x....\n",
            "Step 4\n",
            "obs= [5.] reward= 0 done= False\n",
            ".....x.....\n",
            "Step 5\n",
            "obs= [4.] reward= 0 done= False\n",
            "....x......\n",
            "Step 6\n",
            "obs= [3.] reward= 0 done= False\n",
            "...x.......\n",
            "Step 7\n",
            "obs= [2.] reward= 0 done= False\n",
            "..x........\n",
            "Step 8\n",
            "obs= [1.] reward= 0 done= False\n",
            ".x.........\n",
            "Step 9\n",
            "obs= [0.] reward= 1 done= True\n",
            "x..........\n",
            "Goal reached! reward= 1\n"
          ]
        }
      ],
      "source": [
        "env = GoLeftEnv(grid_size=10)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "GO_LEFT = 0\n",
        "# Hardcoded best agent: always go left!\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    print(f\"Step {step + 1}\")\n",
        "    obs, reward, terminated, truncated, info = env.step(GO_LEFT)\n",
        "    done = terminated or truncated\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv1e1qJETfHU"
      },
      "source": [
        "### Try it with Stable-Baselines\n",
        "\n",
        "Once your environment follow the gym interface, it is quite easy to plug in any algorithm from stable-baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PQfLBE28SNDr"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Instantiate the env\n",
        "vec_env = make_vec_env(GoLeftEnv, n_envs=1, env_kwargs=dict(grid_size=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zRV4Q7FVUKB6",
        "outputId": "771991d4-1fca-4096-985b-70859ee73ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.9     |\n",
            "|    ep_rew_mean        | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.413   |\n",
            "|    explained_variance | -1.99    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.00263  |\n",
            "|    value_loss         | 0.00344  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.9     |\n",
            "|    ep_rew_mean        | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.216   |\n",
            "|    explained_variance | -11.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.00275 |\n",
            "|    value_loss         | 0.00328  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 10.1      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.126    |\n",
            "|    explained_variance | -6.47     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -0.000396 |\n",
            "|    value_loss         | 0.00117   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.2      |\n",
            "|    ep_rew_mean        | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 298      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0315  |\n",
            "|    explained_variance | 0.817    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.000101 |\n",
            "|    value_loss         | 0.000502 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.12      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 319       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0256   |\n",
            "|    explained_variance | 0.878     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -6.45e-05 |\n",
            "|    value_loss         | 0.000202  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.1      |\n",
            "|    ep_rew_mean        | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 326      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0145  |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 8.28e-06 |\n",
            "|    value_loss         | 1.65e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.06      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 325       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0355   |\n",
            "|    explained_variance | 0.974     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -2.47e-05 |\n",
            "|    value_loss         | 3.21e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.04      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 333       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0135   |\n",
            "|    explained_variance | 0.994     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -5.63e-06 |\n",
            "|    value_loss         | 3.69e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.04      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 343       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00257  |\n",
            "|    explained_variance | 0.976     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -1.46e-06 |\n",
            "|    value_loss         | 3.5e-05   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.02      |\n",
            "|    ep_rew_mean        | 1         |\n",
            "| time/                 |           |\n",
            "|    fps                | 350       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00664  |\n",
            "|    explained_variance | 0.869     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -8.61e-06 |\n",
            "|    value_loss         | 9.87e-05  |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Train the agent\n",
        "model = A2C(\"MlpPolicy\", env, verbose=1).learn(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbeiF0RUN-p",
        "outputId": "4b3959e4-9df0-4365-fd86-f42adb0e02c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "Action:  [0]\n",
            "obs= [[8.]] reward= [0.] done= [False]\n",
            "........x..\n",
            "Step 2\n",
            "Action:  [0]\n",
            "obs= [[7.]] reward= [0.] done= [False]\n",
            ".......x...\n",
            "Step 3\n",
            "Action:  [0]\n",
            "obs= [[6.]] reward= [0.] done= [False]\n",
            "......x....\n",
            "Step 4\n",
            "Action:  [0]\n",
            "obs= [[5.]] reward= [0.] done= [False]\n",
            ".....x.....\n",
            "Step 5\n",
            "Action:  [0]\n",
            "obs= [[4.]] reward= [0.] done= [False]\n",
            "....x......\n",
            "Step 6\n",
            "Action:  [0]\n",
            "obs= [[3.]] reward= [0.] done= [False]\n",
            "...x.......\n",
            "Step 7\n",
            "Action:  [0]\n",
            "obs= [[2.]] reward= [0.] done= [False]\n",
            "..x........\n",
            "Step 8\n",
            "Action:  [0]\n",
            "obs= [[1.]] reward= [0.] done= [False]\n",
            ".x.........\n",
            "Step 9\n",
            "Action:  [0]\n",
            "obs= [[9.]] reward= [1.] done= [ True]\n",
            ".........x.\n",
            "Goal reached! reward= [1.]\n"
          ]
        }
      ],
      "source": [
        "# Test the trained agent\n",
        "# using the vecenv\n",
        "obs = vec_env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    print(\"Action: \", action)\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    vec_env.render()\n",
        "    if done:\n",
        "        # Note that the VecEnv resets automatically\n",
        "        # when a done signal is encountered\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOggIa9sU--b"
      },
      "source": [
        "## It is your turn now, be creative!\n",
        "\n",
        "As an exercise, that's now your turn to build a custom gym environment.\n",
        "There is no constrain about what to do, be creative! (but not too creative, there is not enough time for that)\n",
        "\n",
        "If you don't have any idea, here is is a list of the environment you can implement:\n",
        "- Transform the discrete grid world to a continuous one, you will need to change a bit the logic and the action space\n",
        "- Create a 2D grid world and add walls\n",
        "- Create a tic-tac-toe game\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBDp4Pm-Uh4D",
        "outputId": "30daaba8-e809-4de3-8111-5cff0785d66c"
      },
      "outputs": [],
      "source": [
        "# Tic Tac Toe environment\n",
        "\n",
        "class TicTacToeEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Environment that follows gym interface.\n",
        "    This is a simple env where the agent must learn to play tic tac toe\n",
        "    \"\"\"\n",
        "\n",
        "    # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "    metadata = {\"render_modes\": [\"console\"]}\n",
        "    AGENT_TURN = 1\n",
        "    RANDOM_TURN = 2\n",
        "\n",
        "    def __init__(self, grid_size=3, render_mode=\"console\"):\n",
        "        super(TicTacToeEnv, self).__init__()\n",
        "        self.render_mode = render_mode\n",
        "        self.turn = np.random.choice([self.AGENT_TURN, self.RANDOM_TURN])\n",
        "        self.grid_size = grid_size\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=2, shape=(grid_size * grid_size,), dtype=np.int8 #flattened board instead of nxn\n",
        "        )\n",
        "        self.board = np.zeros((grid_size * grid_size,), dtype=np.int8)\n",
        "        # action space is picking one of the boxes\n",
        "        self.action_space = spaces.Discrete(grid_size * grid_size)\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"\n",
        "        Important: the observation must be a numpy array\n",
        "        :return: (np.array)\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed, options=options)\n",
        "        self.board = np.zeros((self.grid_size*self.grid_size,), dtype=np.int8)\n",
        "        self.turn = np.random.choice([self.AGENT_TURN, self.RANDOM_TURN]) #doesn't do shit right now\n",
        "        return np.array(self.board),{}\n",
        "\n",
        "    def step(self, action):\n",
        "        # BUG IS THAT THE AGENT ALWAYS ACTS FIRST\n",
        "        # Agent action\n",
        "        if (self.board[action]!=0):\n",
        "            return(\n",
        "                self.board,\n",
        "                -3,\n",
        "                True, # end the episode if an invalid action is made\n",
        "                False,\n",
        "                {\"invalid_action\":True}\n",
        "            )\n",
        "        self.board[action] = 1 #Agent makes moves\n",
        "        # agent action over\n",
        "        board2d = self.board.reshape((self.grid_size,self.grid_size))\n",
        "        if (np.any(np.all(board2d == 1, axis=1)) or  # rows\n",
        "            np.any(np.all(board2d == 1, axis=0)) or  # columns\n",
        "            np.all(np.diag(board2d) == 1) or         # diagonal\n",
        "            np.all(np.diag(np.fliplr(board2d)) == 1)): # anti-diagonal\n",
        "            return np.array(self.board), 1, True, False, {}\n",
        "\n",
        "        reward = 0\n",
        "        truncated = bool(self.board.flatten().all()) # truncated if all cells are filled\n",
        "        terminated = False\n",
        "        # check if the game is over\n",
        "        if truncated:\n",
        "            return np.array(self.board), reward, terminated, truncated, {}\n",
        "\n",
        "        # RANDOM TURN\n",
        "        valid_moves = np.where(self.board == 0)[0]\n",
        "        ran_action = np.random.choice(valid_moves)\n",
        "        self.board[ran_action] = 2\n",
        "        truncated = bool(self.board.flatten().all()) # truncated if all cells are filled\n",
        "\n",
        "        # check diagonal\n",
        "        board2d = self.board.reshape((self.grid_size,self.grid_size))\n",
        "        if np.all(np.diag(board2d)==1):\n",
        "            terminated = True\n",
        "            reward=-1\n",
        "        # check anti-diagonal\n",
        "        if np.all(np.diag(np.fliplr(board2d)) == 1):\n",
        "            terminated = True\n",
        "            reward = 1\n",
        "        if np.all(np.diag(np.fliplr(board2d)) == 2):\n",
        "            terminated = True\n",
        "            reward = -1\n",
        "\n",
        "        # check rows\n",
        "        if np.any(np.all(board2d == 1,axis=1)):\n",
        "              terminated=True\n",
        "              reward = 1\n",
        "        if np.any(np.all(board2d == 2,axis=1)):\n",
        "              terminated=True\n",
        "              reward=-1\n",
        "        # check columns\n",
        "        if np.any(np.all(board2d == 1,axis=0)):\n",
        "              terminated=True\n",
        "              reward = 1\n",
        "        if np.any(np.all(board2d == 2,axis=0)):\n",
        "              terminated=True\n",
        "              reward=-1\n",
        " \n",
        "        # ----------\n",
        "        return np.array(self.board), reward, terminated, truncated, {}\n",
        "\n",
        "    def render(self):\n",
        "        board2d = self.board.reshape((self.grid_size,self.grid_size))\n",
        "        for i in range(self.grid_size):\n",
        "            for j in range(self.grid_size):\n",
        "              if j == self.grid_size - 1:\n",
        "                  print(board2d[i,j])\n",
        "              else:\n",
        "                  print(board2d[i,j],end=\"|\")             \n",
        "            if i != self.grid_size - 1:\n",
        "                print(\"-\"*(2*self.grid_size-1))\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "bqKyMKv8z_7y"
      },
      "outputs": [],
      "source": [
        "GRID_SIZE = 4\n",
        "env = TicTacToeEnv(grid_size=GRID_SIZE)\n",
        "check_env(env,warn=True)\n",
        "\n",
        "vec_env = make_vec_env(TicTacToeEnv, n_envs=1, env_kwargs=dict(grid_size=GRID_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 4.19     |\n",
            "|    ep_rew_mean     | -2.76    |\n",
            "| time/              |          |\n",
            "|    fps             | 6723     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.49        |\n",
            "|    ep_rew_mean          | -2.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4858        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 0           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012168924 |\n",
            "|    clip_fraction        | 0.0866      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.77       |\n",
            "|    explained_variance   | -0.457      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.061       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0285     |\n",
            "|    value_loss           | 1.37        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 4.87         |\n",
            "|    ep_rew_mean          | -2.77        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 4296         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0084281005 |\n",
            "|    clip_fraction        | 0.0652       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | -0.0791      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0417       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0237      |\n",
            "|    value_loss           | 0.359        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.65        |\n",
            "|    ep_rew_mean          | -2.82       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4158        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010581011 |\n",
            "|    clip_fraction        | 0.0875      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.74       |\n",
            "|    explained_variance   | -0.0656     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0234      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0271     |\n",
            "|    value_loss           | 0.439       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.82        |\n",
            "|    ep_rew_mean          | -2.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4117        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 2           |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010439832 |\n",
            "|    clip_fraction        | 0.0804      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.72       |\n",
            "|    explained_variance   | -0.0613     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0409      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0254     |\n",
            "|    value_loss           | 0.371       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.87        |\n",
            "|    ep_rew_mean          | -2.84       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4072        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010161888 |\n",
            "|    clip_fraction        | 0.0821      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.7        |\n",
            "|    explained_variance   | -0.0672     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.109       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0262     |\n",
            "|    value_loss           | 0.459       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.03        |\n",
            "|    ep_rew_mean          | -2.69       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4043        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011302582 |\n",
            "|    clip_fraction        | 0.0979      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.67       |\n",
            "|    explained_variance   | -0.074      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.22        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0298     |\n",
            "|    value_loss           | 0.445       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.08        |\n",
            "|    ep_rew_mean          | -2.54       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 4012        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010732887 |\n",
            "|    clip_fraction        | 0.0823      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.65       |\n",
            "|    explained_variance   | -0.015      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.408       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0262     |\n",
            "|    value_loss           | 0.627       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.11        |\n",
            "|    ep_rew_mean          | -2.56       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3994        |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010849618 |\n",
            "|    clip_fraction        | 0.0938      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.62       |\n",
            "|    explained_variance   | -0.0131     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.202       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0302     |\n",
            "|    value_loss           | 0.649       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.21        |\n",
            "|    ep_rew_mean          | -2.62       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3965        |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010451252 |\n",
            "|    clip_fraction        | 0.0863      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.6        |\n",
            "|    explained_variance   | -0.0348     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.649       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0275     |\n",
            "|    value_loss           | 0.812       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.13        |\n",
            "|    ep_rew_mean          | -2.65       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3868        |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011104869 |\n",
            "|    clip_fraction        | 0.0932      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.57       |\n",
            "|    explained_variance   | -0.0139     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.329       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0303     |\n",
            "|    value_loss           | 0.877       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.43        |\n",
            "|    ep_rew_mean          | -2.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3881        |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012213038 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.55       |\n",
            "|    explained_variance   | -0.000134   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.275       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0329     |\n",
            "|    value_loss           | 0.887       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.01        |\n",
            "|    ep_rew_mean          | -2.51       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3892        |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010467023 |\n",
            "|    clip_fraction        | 0.0868      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.53       |\n",
            "|    explained_variance   | -0.0497     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.296       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0281     |\n",
            "|    value_loss           | 0.929       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.52        |\n",
            "|    ep_rew_mean          | -2.67       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3904        |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013032853 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.49       |\n",
            "|    explained_variance   | -0.0437     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.373       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    value_loss           | 0.856       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.72        |\n",
            "|    ep_rew_mean          | -2.79       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3914        |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012250599 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.47       |\n",
            "|    explained_variance   | -0.0413     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.441       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    value_loss           | 0.997       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97        |\n",
            "|    ep_rew_mean          | -2.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3919        |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011823593 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.44       |\n",
            "|    explained_variance   | -0.0117     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.382       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    value_loss           | 1           |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.96        |\n",
            "|    ep_rew_mean          | -2.37       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3922        |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013319589 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.39       |\n",
            "|    explained_variance   | -0.0496     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.63        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0324     |\n",
            "|    value_loss           | 1.13        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.2         |\n",
            "|    ep_rew_mean          | -2.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3925        |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012910213 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.37       |\n",
            "|    explained_variance   | -0.0249     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.561       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0328     |\n",
            "|    value_loss           | 1.22        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6.3          |\n",
            "|    ep_rew_mean          | -1.87        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 3930         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0130276615 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.35        |\n",
            "|    explained_variance   | -0.0329      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.416        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.033       |\n",
            "|    value_loss           | 1.25         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.44        |\n",
            "|    ep_rew_mean          | -1.78       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3935        |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014070472 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.33       |\n",
            "|    explained_variance   | -0.00502    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.751       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0353     |\n",
            "|    value_loss           | 1.46        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.01        |\n",
            "|    ep_rew_mean          | -2.11       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3938        |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014176239 |\n",
            "|    clip_fraction        | 0.137       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.3        |\n",
            "|    explained_variance   | -0.0177     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.687       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.037      |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.51        |\n",
            "|    ep_rew_mean          | -1.94       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3943        |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013247669 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.28       |\n",
            "|    explained_variance   | -0.028      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.461       |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0342     |\n",
            "|    value_loss           | 1.57        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.08        |\n",
            "|    ep_rew_mean          | -1.84       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3947        |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013141802 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.25       |\n",
            "|    explained_variance   | -0.0303     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.696       |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0358     |\n",
            "|    value_loss           | 1.56        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.48        |\n",
            "|    ep_rew_mean          | -2.04       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3951        |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015582215 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.22       |\n",
            "|    explained_variance   | -0.0213     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.727       |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0386     |\n",
            "|    value_loss           | 1.64        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.38        |\n",
            "|    ep_rew_mean          | -1.86       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3952        |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013946034 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.17       |\n",
            "|    explained_variance   | -0.0635     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.549       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0358     |\n",
            "|    value_loss           | 1.56        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.45        |\n",
            "|    ep_rew_mean          | -1.42       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3954        |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013789754 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.15       |\n",
            "|    explained_variance   | -0.0278     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.05        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.038      |\n",
            "|    value_loss           | 1.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.51        |\n",
            "|    ep_rew_mean          | -1.45       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3956        |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013658075 |\n",
            "|    clip_fraction        | 0.137       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.11       |\n",
            "|    explained_variance   | 0.00221     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.75        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0351     |\n",
            "|    value_loss           | 1.8         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6.62         |\n",
            "|    ep_rew_mean          | -1.44        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 3959         |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0135586085 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.08        |\n",
            "|    explained_variance   | 0.00426      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.986        |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.0388      |\n",
            "|    value_loss           | 2            |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.51        |\n",
            "|    ep_rew_mean          | -1.12       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3957        |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013750097 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.05       |\n",
            "|    explained_variance   | 0.00853     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.725       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0395     |\n",
            "|    value_loss           | 1.96        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6.77       |\n",
            "|    ep_rew_mean          | -1.24      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3957       |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 15         |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01512878 |\n",
            "|    clip_fraction        | 0.168      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.01      |\n",
            "|    explained_variance   | -0.0153    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.985      |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.0411    |\n",
            "|    value_loss           | 2.08       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6.4          |\n",
            "|    ep_rew_mean          | -1.33        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 3958         |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0135748945 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.99        |\n",
            "|    explained_variance   | -0.024       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.784        |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.0367      |\n",
            "|    value_loss           | 2.08         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.71        |\n",
            "|    ep_rew_mean          | -1.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3960        |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014187566 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.98       |\n",
            "|    explained_variance   | 0.00849     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.04        |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0382     |\n",
            "|    value_loss           | 2.2         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.5         |\n",
            "|    ep_rew_mean          | -1.26       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3962        |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015250081 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.95       |\n",
            "|    explained_variance   | 0.0378      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.666       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0416     |\n",
            "|    value_loss           | 1.94        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.68        |\n",
            "|    ep_rew_mean          | -0.82       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3963        |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015311866 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | 0.000868    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.94        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0409     |\n",
            "|    value_loss           | 1.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.45        |\n",
            "|    ep_rew_mean          | -0.99       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3965        |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014605904 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.91       |\n",
            "|    explained_variance   | 0.0327      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.682       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.041      |\n",
            "|    value_loss           | 1.85        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.64        |\n",
            "|    ep_rew_mean          | -0.89       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3967        |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015192196 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.91       |\n",
            "|    explained_variance   | 0.00109     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.775       |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0408     |\n",
            "|    value_loss           | 2.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.77        |\n",
            "|    ep_rew_mean          | -0.59       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3968        |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016432239 |\n",
            "|    clip_fraction        | 0.178       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | 0.00539     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.03        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.0443     |\n",
            "|    value_loss           | 2.05        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.57        |\n",
            "|    ep_rew_mean          | -0.62       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3970        |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015993256 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 0.028       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.934       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.0402     |\n",
            "|    value_loss           | 2.05        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.9         |\n",
            "|    ep_rew_mean          | -0.78       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3971        |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016952354 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 0.0639      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.719       |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0423     |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.44        |\n",
            "|    ep_rew_mean          | -0.26       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3971        |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017297793 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.0302      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.08        |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0452     |\n",
            "|    value_loss           | 2.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.82        |\n",
            "|    ep_rew_mean          | -0.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3972        |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014378008 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.0506      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.938       |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.0394     |\n",
            "|    value_loss           | 1.88        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.82        |\n",
            "|    ep_rew_mean          | -0.23       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3973        |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014932453 |\n",
            "|    clip_fraction        | 0.182       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.0276      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.949       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0425     |\n",
            "|    value_loss           | 1.76        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.82        |\n",
            "|    ep_rew_mean          | -0.24       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3974        |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017627591 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | 0.0456      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.759       |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0441     |\n",
            "|    value_loss           | 1.77        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 6.53      |\n",
            "|    ep_rew_mean          | -0.27     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 3974      |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 22        |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0143838 |\n",
            "|    clip_fraction        | 0.167     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.62     |\n",
            "|    explained_variance   | 0.00409   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.616     |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | -0.0401   |\n",
            "|    value_loss           | 1.59      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.38        |\n",
            "|    ep_rew_mean          | -0.18       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3975        |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015795311 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.0325      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.772       |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.0441     |\n",
            "|    value_loss           | 1.64        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6.68       |\n",
            "|    ep_rew_mean          | -0.1       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3970       |\n",
            "|    iterations           | 46         |\n",
            "|    time_elapsed         | 23         |\n",
            "|    total_timesteps      | 94208      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01714405 |\n",
            "|    clip_fraction        | 0.198      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.55      |\n",
            "|    explained_variance   | 0.0478     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.673      |\n",
            "|    n_updates            | 450        |\n",
            "|    policy_gradient_loss | -0.045     |\n",
            "|    value_loss           | 1.54       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.53        |\n",
            "|    ep_rew_mean          | -0.05       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3969        |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 96256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015130393 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.0164      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.698       |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.0399     |\n",
            "|    value_loss           | 1.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.56        |\n",
            "|    ep_rew_mean          | -0.02       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3970        |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014179682 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | 0.0235      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.769       |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.041      |\n",
            "|    value_loss           | 1.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.31        |\n",
            "|    ep_rew_mean          | -0.21       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3971        |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014815916 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0.0729      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.506       |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0405     |\n",
            "|    value_loss           | 1.54        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6.21       |\n",
            "|    ep_rew_mean          | 0.04       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3972       |\n",
            "|    iterations           | 50         |\n",
            "|    time_elapsed         | 25         |\n",
            "|    total_timesteps      | 102400     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01487631 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.43      |\n",
            "|    explained_variance   | 0.0281     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.72       |\n",
            "|    n_updates            | 490        |\n",
            "|    policy_gradient_loss | -0.039     |\n",
            "|    value_loss           | 1.57       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6.31       |\n",
            "|    ep_rew_mean          | 0.19       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3972       |\n",
            "|    iterations           | 51         |\n",
            "|    time_elapsed         | 26         |\n",
            "|    total_timesteps      | 104448     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01455951 |\n",
            "|    clip_fraction        | 0.18       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.42      |\n",
            "|    explained_variance   | 0.0801     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.525      |\n",
            "|    n_updates            | 500        |\n",
            "|    policy_gradient_loss | -0.0416    |\n",
            "|    value_loss           | 1.5        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.51        |\n",
            "|    ep_rew_mean          | 0.28        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3962        |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015117384 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.0781      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.518       |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.0393     |\n",
            "|    value_loss           | 1.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.36        |\n",
            "|    ep_rew_mean          | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3962        |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013752507 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.075       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.643       |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.0372     |\n",
            "|    value_loss           | 1.42        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6.36       |\n",
            "|    ep_rew_mean          | 0.22       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3963       |\n",
            "|    iterations           | 54         |\n",
            "|    time_elapsed         | 27         |\n",
            "|    total_timesteps      | 110592     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01439871 |\n",
            "|    clip_fraction        | 0.172      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.33      |\n",
            "|    explained_variance   | 0.0819     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.511      |\n",
            "|    n_updates            | 530        |\n",
            "|    policy_gradient_loss | -0.0399    |\n",
            "|    value_loss           | 1.12       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.19        |\n",
            "|    ep_rew_mean          | 0.22        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3964        |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013430507 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.119       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.513       |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.0347     |\n",
            "|    value_loss           | 1.22        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.41        |\n",
            "|    ep_rew_mean          | 0.16        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3965        |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013982247 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.0849      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.511       |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.0379     |\n",
            "|    value_loss           | 1.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.81        |\n",
            "|    ep_rew_mean          | 0.42        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3967        |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013823396 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.0753      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.497       |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.0351     |\n",
            "|    value_loss           | 1.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.31        |\n",
            "|    ep_rew_mean          | 0.37        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3967        |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 118784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014700393 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 0.137       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.446       |\n",
            "|    n_updates            | 570         |\n",
            "|    policy_gradient_loss | -0.0393     |\n",
            "|    value_loss           | 1.24        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6.07         |\n",
            "|    ep_rew_mean          | 0.28         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 3966         |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0133866165 |\n",
            "|    clip_fraction        | 0.153        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | 0.158        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.376        |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.0358      |\n",
            "|    value_loss           | 0.993        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.03        |\n",
            "|    ep_rew_mean          | 0.44        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3967        |\n",
            "|    iterations           | 60          |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015417816 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.143       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.443       |\n",
            "|    n_updates            | 590         |\n",
            "|    policy_gradient_loss | -0.0366     |\n",
            "|    value_loss           | 1.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.07        |\n",
            "|    ep_rew_mean          | 0.29        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3968        |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012792451 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.107       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.464       |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.0343     |\n",
            "|    value_loss           | 1.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.09        |\n",
            "|    ep_rew_mean          | 0.23        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3969        |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 126976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014247725 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.115       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.473       |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.0351     |\n",
            "|    value_loss           | 1.26        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.14        |\n",
            "|    ep_rew_mean          | 0.24        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3970        |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014261374 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.035      |\n",
            "|    value_loss           | 1.07        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.96        |\n",
            "|    ep_rew_mean          | 0.31        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3971        |\n",
            "|    iterations           | 64          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012516271 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.173       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.588       |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | -0.0361     |\n",
            "|    value_loss           | 1.11        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.09        |\n",
            "|    ep_rew_mean          | 0.27        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3972        |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013618726 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.191       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.379       |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.0337     |\n",
            "|    value_loss           | 1.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.96        |\n",
            "|    ep_rew_mean          | 0.45        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3972        |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 34          |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015094416 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.174       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.497       |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.0384     |\n",
            "|    value_loss           | 1.04        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.77        |\n",
            "|    ep_rew_mean          | 0.49        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3973        |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 34          |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015360843 |\n",
            "|    clip_fraction        | 0.178       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.411       |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | -0.038      |\n",
            "|    value_loss           | 0.966       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.88        |\n",
            "|    ep_rew_mean          | 0.61        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3974        |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014281602 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 0.221       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.235       |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.036      |\n",
            "|    value_loss           | 0.951       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.95        |\n",
            "|    ep_rew_mean          | 0.47        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3975        |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014171265 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.181       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.451       |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.0333     |\n",
            "|    value_loss           | 0.805       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.5         |\n",
            "|    ep_rew_mean          | 0.52        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3975        |\n",
            "|    iterations           | 70          |\n",
            "|    time_elapsed         | 36          |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013952916 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 0.194       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.456       |\n",
            "|    n_updates            | 690         |\n",
            "|    policy_gradient_loss | -0.0353     |\n",
            "|    value_loss           | 1.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.81        |\n",
            "|    ep_rew_mean          | 0.41        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3976        |\n",
            "|    iterations           | 71          |\n",
            "|    time_elapsed         | 36          |\n",
            "|    total_timesteps      | 145408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016212761 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.175       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.283       |\n",
            "|    n_updates            | 700         |\n",
            "|    policy_gradient_loss | -0.0355     |\n",
            "|    value_loss           | 0.941       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.84        |\n",
            "|    ep_rew_mean          | 0.59        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3976        |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014278582 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.216       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.0327     |\n",
            "|    value_loss           | 0.856       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.94        |\n",
            "|    ep_rew_mean          | 0.56        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3976        |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015405903 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.02       |\n",
            "|    explained_variance   | 0.234       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.241       |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.0344     |\n",
            "|    value_loss           | 0.858       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.51       |\n",
            "|    ep_rew_mean          | 0.8        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3975       |\n",
            "|    iterations           | 74         |\n",
            "|    time_elapsed         | 38         |\n",
            "|    total_timesteps      | 151552     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01228123 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.02      |\n",
            "|    explained_variance   | 0.209      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.212      |\n",
            "|    n_updates            | 730        |\n",
            "|    policy_gradient_loss | -0.0307    |\n",
            "|    value_loss           | 0.748      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.64        |\n",
            "|    ep_rew_mean          | 0.46        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3976        |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013398973 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.34        |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | -0.034      |\n",
            "|    value_loss           | 0.718       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.68       |\n",
            "|    ep_rew_mean          | 0.73       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3976       |\n",
            "|    iterations           | 76         |\n",
            "|    time_elapsed         | 39         |\n",
            "|    total_timesteps      | 155648     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01415373 |\n",
            "|    clip_fraction        | 0.148      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.966     |\n",
            "|    explained_variance   | 0.181      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.54       |\n",
            "|    n_updates            | 750        |\n",
            "|    policy_gradient_loss | -0.0315    |\n",
            "|    value_loss           | 0.913      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.41        |\n",
            "|    ep_rew_mean          | 0.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3974        |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015075275 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.963      |\n",
            "|    explained_variance   | 0.237       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.236       |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.0354     |\n",
            "|    value_loss           | 0.727       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.52        |\n",
            "|    ep_rew_mean          | 0.58        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3974        |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014376814 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.926      |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.354       |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    value_loss           | 0.756       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.6         |\n",
            "|    ep_rew_mean          | 0.56        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3971        |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 161792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015645428 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.918      |\n",
            "|    explained_variance   | 0.217       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.423       |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.0327     |\n",
            "|    value_loss           | 0.874       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.5         |\n",
            "|    ep_rew_mean          | 0.52        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3970        |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013370293 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.941      |\n",
            "|    explained_variance   | 0.172       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 0.808       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.55        |\n",
            "|    ep_rew_mean          | 0.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3970        |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014871011 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.938      |\n",
            "|    explained_variance   | 0.156       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.53        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.0319     |\n",
            "|    value_loss           | 0.927       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.57         |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 3962         |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0134577025 |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.921       |\n",
            "|    explained_variance   | 0.261        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.194        |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.0271      |\n",
            "|    value_loss           | 0.555        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.67        |\n",
            "|    ep_rew_mean          | 0.49        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3957        |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013168943 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.944      |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.3         |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.031      |\n",
            "|    value_loss           | 0.779       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 5.38      |\n",
            "|    ep_rew_mean          | 0.67      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 3950      |\n",
            "|    iterations           | 84        |\n",
            "|    time_elapsed         | 43        |\n",
            "|    total_timesteps      | 172032    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0133833 |\n",
            "|    clip_fraction        | 0.154     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.921    |\n",
            "|    explained_variance   | 0.265     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.524     |\n",
            "|    n_updates            | 830       |\n",
            "|    policy_gradient_loss | -0.0301   |\n",
            "|    value_loss           | 0.863     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.47        |\n",
            "|    ep_rew_mean          | 0.54        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3949        |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014551535 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.896      |\n",
            "|    explained_variance   | 0.267       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.366       |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.0296     |\n",
            "|    value_loss           | 0.701       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.26        |\n",
            "|    ep_rew_mean          | 0.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3948        |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013966927 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.914      |\n",
            "|    explained_variance   | 0.209       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.502       |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -0.0292     |\n",
            "|    value_loss           | 0.787       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.64        |\n",
            "|    ep_rew_mean          | 0.55        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3948        |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011607174 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.907      |\n",
            "|    explained_variance   | 0.298       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.374       |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.0298     |\n",
            "|    value_loss           | 0.803       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.6         |\n",
            "|    ep_rew_mean          | 0.52        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3948        |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015522078 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.885      |\n",
            "|    explained_variance   | 0.177       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.381       |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.0317     |\n",
            "|    value_loss           | 0.697       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.48        |\n",
            "|    ep_rew_mean          | 0.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3947        |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 46          |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013519366 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.9        |\n",
            "|    explained_variance   | 0.29        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.237       |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.0305     |\n",
            "|    value_loss           | 0.713       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.63        |\n",
            "|    ep_rew_mean          | 0.68        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3947        |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 46          |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013993675 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.892      |\n",
            "|    explained_variance   | 0.279       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.297       |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    value_loss           | 0.828       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.31        |\n",
            "|    ep_rew_mean          | 0.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3946        |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014197668 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.871      |\n",
            "|    explained_variance   | 0.26        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.19        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.0311     |\n",
            "|    value_loss           | 0.717       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.75       |\n",
            "|    ep_rew_mean          | 0.42       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3945       |\n",
            "|    iterations           | 92         |\n",
            "|    time_elapsed         | 47         |\n",
            "|    total_timesteps      | 188416     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01628149 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.873     |\n",
            "|    explained_variance   | 0.266      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.219      |\n",
            "|    n_updates            | 910        |\n",
            "|    policy_gradient_loss | -0.0313    |\n",
            "|    value_loss           | 0.735      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.51        |\n",
            "|    ep_rew_mean          | 0.48        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3944        |\n",
            "|    iterations           | 93          |\n",
            "|    time_elapsed         | 48          |\n",
            "|    total_timesteps      | 190464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015589508 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.866      |\n",
            "|    explained_variance   | 0.254       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.48        |\n",
            "|    n_updates            | 920         |\n",
            "|    policy_gradient_loss | -0.0321     |\n",
            "|    value_loss           | 0.965       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.29        |\n",
            "|    ep_rew_mean          | 0.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3943        |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 48          |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015883546 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.871      |\n",
            "|    explained_variance   | 0.215       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.0292     |\n",
            "|    value_loss           | 0.845       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.42        |\n",
            "|    ep_rew_mean          | 0.67        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3943        |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014385792 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.863      |\n",
            "|    explained_variance   | 0.255       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.301       |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.0317     |\n",
            "|    value_loss           | 0.704       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.33        |\n",
            "|    ep_rew_mean          | 0.75        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3943        |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012907337 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.849      |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.369       |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    value_loss           | 0.613       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.41        |\n",
            "|    ep_rew_mean          | 0.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3943        |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016099127 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.843      |\n",
            "|    explained_variance   | 0.324       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.031      |\n",
            "|    value_loss           | 0.664       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.4         |\n",
            "|    ep_rew_mean          | 0.61        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3942        |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015482125 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.844      |\n",
            "|    explained_variance   | 0.287       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.286       |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.0317     |\n",
            "|    value_loss           | 0.553       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.33        |\n",
            "|    ep_rew_mean          | 0.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3942        |\n",
            "|    iterations           | 99          |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 202752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014203807 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.841      |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.274       |\n",
            "|    n_updates            | 980         |\n",
            "|    policy_gradient_loss | -0.0275     |\n",
            "|    value_loss           | 0.627       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.27        |\n",
            "|    ep_rew_mean          | 0.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3942        |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015166878 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.838      |\n",
            "|    explained_variance   | 0.222       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | -0.0314     |\n",
            "|    value_loss           | 0.614       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.5         |\n",
            "|    ep_rew_mean          | 0.65        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3940        |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 206848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018109107 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.848      |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.154       |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    value_loss           | 0.595       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.61        |\n",
            "|    ep_rew_mean          | 0.55        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3938        |\n",
            "|    iterations           | 102         |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 208896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017505888 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.826      |\n",
            "|    explained_variance   | 0.303       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.298       |\n",
            "|    n_updates            | 1010        |\n",
            "|    policy_gradient_loss | -0.0299     |\n",
            "|    value_loss           | 0.571       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.39        |\n",
            "|    ep_rew_mean          | 0.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3937        |\n",
            "|    iterations           | 103         |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 210944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012909109 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | 0.266       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.504       |\n",
            "|    n_updates            | 1020        |\n",
            "|    policy_gradient_loss | -0.0285     |\n",
            "|    value_loss           | 0.746       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.38        |\n",
            "|    ep_rew_mean          | 0.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3938        |\n",
            "|    iterations           | 104         |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012977427 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.829      |\n",
            "|    explained_variance   | 0.306       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.221       |\n",
            "|    n_updates            | 1030        |\n",
            "|    policy_gradient_loss | -0.0273     |\n",
            "|    value_loss           | 0.564       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.58        |\n",
            "|    ep_rew_mean          | 0.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3932        |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013711655 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.821      |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.319       |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 0.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.47        |\n",
            "|    ep_rew_mean          | 0.86        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3931        |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 217088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013536068 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.821      |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.12        |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.0292     |\n",
            "|    value_loss           | 0.542       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.42       |\n",
            "|    ep_rew_mean          | 0.71       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3931       |\n",
            "|    iterations           | 107        |\n",
            "|    time_elapsed         | 55         |\n",
            "|    total_timesteps      | 219136     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01651721 |\n",
            "|    clip_fraction        | 0.153      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.845     |\n",
            "|    explained_variance   | 0.204      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.132      |\n",
            "|    n_updates            | 1060       |\n",
            "|    policy_gradient_loss | -0.0298    |\n",
            "|    value_loss           | 0.443      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.54        |\n",
            "|    ep_rew_mean          | 0.68        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3930        |\n",
            "|    iterations           | 108         |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013282768 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.822      |\n",
            "|    explained_variance   | 0.297       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.261       |\n",
            "|    n_updates            | 1070        |\n",
            "|    policy_gradient_loss | -0.0307     |\n",
            "|    value_loss           | 0.574       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.39        |\n",
            "|    ep_rew_mean          | 0.89        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3931        |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 223232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017112978 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.814      |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.283       |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | -0.0287     |\n",
            "|    value_loss           | 0.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.36        |\n",
            "|    ep_rew_mean          | 0.78        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3932        |\n",
            "|    iterations           | 110         |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 225280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016254507 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.834      |\n",
            "|    explained_variance   | 0.188       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.265       |\n",
            "|    n_updates            | 1090        |\n",
            "|    policy_gradient_loss | -0.0276     |\n",
            "|    value_loss           | 0.448       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.34        |\n",
            "|    ep_rew_mean          | 0.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3932        |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 227328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018638114 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.827      |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.208       |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.031      |\n",
            "|    value_loss           | 0.481       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.14        |\n",
            "|    ep_rew_mean          | 0.83        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3933        |\n",
            "|    iterations           | 112         |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015258977 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.805      |\n",
            "|    explained_variance   | 0.279       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.208       |\n",
            "|    n_updates            | 1110        |\n",
            "|    policy_gradient_loss | -0.0286     |\n",
            "|    value_loss           | 0.588       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.33        |\n",
            "|    ep_rew_mean          | 0.62        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3933        |\n",
            "|    iterations           | 113         |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 231424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018557508 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.797      |\n",
            "|    explained_variance   | 0.198       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.202       |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | -0.03       |\n",
            "|    value_loss           | 0.423       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.46        |\n",
            "|    ep_rew_mean          | 0.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3932        |\n",
            "|    iterations           | 114         |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 233472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016399352 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.8        |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.276       |\n",
            "|    n_updates            | 1130        |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 0.575       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.3         |\n",
            "|    ep_rew_mean          | 0.84        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3933        |\n",
            "|    iterations           | 115         |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015555362 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.782      |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.166       |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | -0.0297     |\n",
            "|    value_loss           | 0.414       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.64        |\n",
            "|    ep_rew_mean          | 0.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3933        |\n",
            "|    iterations           | 116         |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014078315 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.809      |\n",
            "|    explained_variance   | 0.212       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.103       |\n",
            "|    n_updates            | 1150        |\n",
            "|    policy_gradient_loss | -0.0289     |\n",
            "|    value_loss           | 0.437       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.38        |\n",
            "|    ep_rew_mean          | 0.84        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 3933        |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 239616      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012374968 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.804      |\n",
            "|    explained_variance   | 0.3         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.119       |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | -0.0281     |\n",
            "|    value_loss           | 0.424       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.57       |\n",
            "|    ep_rew_mean          | 0.45       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 3933       |\n",
            "|    iterations           | 118        |\n",
            "|    time_elapsed         | 61         |\n",
            "|    total_timesteps      | 241664     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01576956 |\n",
            "|    clip_fraction        | 0.159      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.803     |\n",
            "|    explained_variance   | 0.268      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.316      |\n",
            "|    n_updates            | 1170       |\n",
            "|    policy_gradient_loss | -0.0316    |\n",
            "|    value_loss           | 0.435      |\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1).learn(240000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|1|0|0\n",
            "-------\n",
            "0|2|0|0\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "obs = vec_env.reset()\n",
        "\n",
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "2|0|0|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|2|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|1|0\n",
            "-------\n",
            "2|0|0|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|2|0|0\n",
            "-------\n",
            "0|0|0|1\n",
            "-------\n",
            "2|0|1|0\n",
            "-------\n",
            "2|0|0|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|2|0|0\n",
            "-------\n",
            "2|0|0|1\n",
            "-------\n",
            "2|0|1|1\n",
            "-------\n",
            "2|0|0|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "reward= [1.] done [ True]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2|0|1|2\n",
            "-------\n",
            "2|0|2|1\n",
            "-------\n",
            "1|0|2|1\n",
            "-------\n",
            "1|0|2|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2|0|1|2\n",
            "-------\n",
            "2|1|2|1\n",
            "-------\n",
            "1|0|2|1\n",
            "-------\n",
            "1|2|2|1\n",
            "reward= [0.] done [False]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "-------\n",
            "0|0|0|0\n",
            "reward= [-1.] done [ True]\n"
          ]
        }
      ],
      "source": [
        "action , _ = model.predict(obs,deterministic=True)\n",
        "obs, reward, done, info = vec_env.step(action)\n",
        "vec_env.render()\n",
        "print(\"reward=\", reward, \"done\", done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3201c96db5836b171d01fee72ea1be894646622d4b41771abf25c98b548a611d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
